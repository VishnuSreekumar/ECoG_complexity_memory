---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
#install.packages("mediation")
#install.packages("car")
library("mediation")
library("car")

mydata = read.csv("sa_ent_dat.csv")
mydata = as.data.frame(scale(mydata))
# Full fit needs to be done with PLS or some method that accounts for correlated variables.
# full.fit <- glm(accuracy ~ t_band_power + slope + sa_ent, data = mydata)
# summary(full.fit)

### MEDIATION ANALYSIS

#1. Is the power to accuracy relationship mediated by slope?
model.0 <- lm(accuracy ~ t_band_power, data = mydata)
summary(model.0)

model.M <- lm(slope ~ t_band_power, data = mydata) # mediator model
summary(model.M)

model.Y <- lm(accuracy ~ t_band_power + slope, data = mydata)
summary(model.Y)


```

```{r}
results1 <- mediate(model.M, model.Y, treat='t_band_power', mediator='slope',
                   boot=TRUE, sims=5000)
summary(results1)
```

```{r}
#2. Is the power to accuracy relationship mediated by sampEn?
model.0 <- lm(accuracy ~ t_band_power, data = mydata)
summary(model.0)

model.M <- lm(sa_ent ~ t_band_power, data = mydata) # mediator model
summary(model.M)

model.Y <- lm(accuracy ~ t_band_power + sa_ent, data = mydata)
summary(model.Y)
```

```{r}
results2 <- mediate(model.M, model.Y, treat='t_band_power', mediator='sa_ent',
                   boot=TRUE, sims=5000)
summary(results2)
```

```{r}
#3. Is the slope to accuracy relationship mediated by sampEn?
model.0 <- lm(accuracy ~ slope, data = mydata)
summary(model.0)

model.M <- lm(sa_ent ~ slope, data = mydata) # mediator model
summary(model.M)

model.Y <- lm(accuracy ~ slope + sa_ent, data = mydata)
summary(model.Y)
```

```{r}
results3 <- mediate(model.M, model.Y, treat='slope', mediator='sa_ent',
                   boot=TRUE, sims=5000)
summary(results3)
```

```{r}
## Mediation may not be the most appropriate analysis
# Mediation tests a causal chain: X --> M --> Y.
# #1 and #2 above. Change in low freq power causes change in slope (or sampEn) and change in slope (or sampEn) causes change in performance -- this mediation is tested in #1 and #2 above. May be justifiable.

# #2 above. Change in slope causes change in entropy is a weird thing to test. More likely is that the same underlying activity changes caused both slope and entropy to change. This should just be tested using multiple linear regression and looking at unique and shared variance, etc. This possibility also holds for both #1 and #2 --> the same activity changes cause parallel changes in power, slope, and entropy. So MLR is appropriate for all analyses. 

# R package 'yhat' provides commanility analyses. 

#install.packages("yhat")
library("yhat")
mydata = read.csv("sa_ent_dat.csv")
mydata = as.data.frame(scale(mydata))
# Do all possible subsets regression
aps.results <- aps(mydata,"accuracy",c("t_band_power","slope","sa_ent"))
aps.results
#commonality(aps.results)
citation("yhat")
```


```{r}
commonalityCoefficients(mydata, "accuracy",c("t_band_power","slope","sa_ent"), imat=FALSE)

pmat = matrix(c(mydata$slope,mydata$sa_ent),nrow=length(mydata$slope),ncol=2)
rcorr(pmat, type="spearman")

res2 = rcorr(as.matrix(mydata), type = c("spearman"))
res2$r
res2$P
```



```{r}
lm.out<-lm(accuracy~t_band_power+slope+sa_ent,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)
```

```{r}
lm.out<-lm(accuracy~t_band_power+sa_ent,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)
```
```{r}
lm.out<-lm(accuracy~t_band_power+slope,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)
```

```{r}
## ASSESSING LINEAR REGRESSION ASSUMPTIONS

library("car")
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(lm.out)
# plot studentized residuals vs. fitted values 
spreadLevelPlot(lm.out)

# Test for Autocorrelated Errors
durbinWatsonTest(lm.out)

# Model assumptions
# install.packages("gvlma")
library("gvlma")
gvmodel <- gvlma(lm.out) 
summary(gvmodel)

# Evaluate Collinearity
vif(lm.out) # variance inflation factors 
sqrt(vif(lm.out)) #> 2 # problem?

# Assessing Outliers
outlierTest(lm.out) # Bonferonni p-value for most extreme obs
qqPlot(lm.out, main="QQ Plot") #qq plot for studentized resid 
leveragePlots(lm.out) # leverage plots


# Non-normality of residuals
qqPlot(lm.out, main="QQ Plot")

library(MASS)
sresid <- studres(lm.out) 
hist(sresid, freq=FALSE, 
   main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40) 
yfit<-dnorm(xfit) 
lines(xfit, yfit)

# Influence Plot 
influencePlot(lm.out,	id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
```

```{r}
# Relative weights
relweights = rlw(mydata, "accuracy",c("t_band_power","slope","sa_ent"))
#sum(relweights) # should sum to multiple R-squared of the regression
```

```{r}
# Calculate partial correlations
#install.packages("ppcor")
library("ppcor")
pcor(mydata, method = "spearman")  # partial correlation with variation from other variables only removed from both variables of the pair
spcorr = spcor(mydata, method = "spearman")  # semi-partial correlation with variation from other variables only removed from the second variable of the pair
spcorr$estimate
# What we want are the semi-partial correlations between power/slope/entropy and accuracy (second variable)
# power ~ accuracy Spearman's spc = -0.31, p=.048
# slope ~ accuracy                   0.09, p = .562
# sa_ent ~ accuracy                  0.23, p = .154
```

```{r}
## PARTIAL LEAST SQUARES REGRESSION 
#  since we have correlated IVs

#install.packages("plsdepot")
#install.packages("pls")
library(pls)
plsfit1 <- plsr(accuracy ~ t_band_power + slope + sa_ent, ncomp = 2, data = mydata, validation = "LOO")
summary(plsfit1)

plot(RMSEP(plsfit1), legendpos = "topright")

plot(plsfit1, plottype = "scores", comps = 1:2)
explvar(plsfit1)


# Prediction exercise
trainrows = sample.int(43, size = 21)
testrows  = setdiff(1:43,trainrows)
accTrain = mydata[trainrows,]
accTest = mydata[head(testrows,-1),]
plsfit1 <- plsr(accuracy ~ t_band_power + slope + sa_ent, data = accTrain, validation = "CV")
summary(plsfit1)
predictedAcc = predict(plsfit1, newdata = accTest)
# Test set RMSEP
RMSEP(plsfit1, newdata = accTest)

predplot(plsfit1, ncomp = 2, newdata = accTest, asp = 1, line = TRUE)

# Selecting number of components using cross validation
ncomp.onesigma <- selectNcomp(plsfit1, method = "onesigma", plot = TRUE, ylim = c(.18, 2))
ncomp.permut <- selectNcomp(plsfit1, method = "randomization", plot = TRUE, ylim = c(.18, 2))


```

```{r}
## RIDGE REGRESSION
#install.packages("tidyverse")
#install.packages("broom")
#install.packages("glmnet")
library(tidyverse)
library(broom)
library(glmnet)
```

```{r}
lm.out<-lm(accuracy~t_band_power+slope,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)
```
```{r}
lm.out<-lm(accuracy~t_band_power+sa_ent,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)
```

```{r}
lm.out<-lm(accuracy~t_band_power*slope,data=mydata)
#calc.yhat(lm.out,prec=3)
#effect.size(lm.out)
regr(lm.out)  # report beta weights, commonality coefs, and effect sizes

aps.results <- aps(mydata,"accuracy",c("t_band_power","slope","sa_ent"))
domOut = dominance(aps.results)
dombin(domOut)

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).
